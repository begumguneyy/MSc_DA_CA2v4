# MSc_DA_CA2v4

In this project, Google Colab and Jupyter Notebook were used as the environment. 
Spark was selected as the distributed data processing environment. 
A comparison was made between MySQL and MongoDB as data storage methods. 
The most challenging part of the project was gleaning data from the Twitter API. 
In my first attempt, I tried data collection using Twitter API keys and tokens with the help of the website 'https://datascienceparichay.com/article/get-data-from-twitter-api-in-python-step-by-step-guide/'. However, this method took a long time to collect data for large datasets and my computer couldn't handle it, so I had to change the approach. 
In my second attempt, I tried to collect Twitter API data using 'https://github.com/JustAnotherArchivist/snscrape.git'. 
After successfully collecting the data, I will proceed to write the code for the required parts of the project and finally write my report based on the results obtained.
